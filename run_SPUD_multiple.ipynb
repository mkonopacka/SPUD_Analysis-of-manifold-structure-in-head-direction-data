{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run dimensionality reduction\n",
    "This is a part of `run_SPUD_multiple_tests.py` script. Running this notebook will:\n",
    "- load projection data from pickle files\n",
    "- ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and loading general params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from ./general_params/general_params.pkl...\n",
      "General params used for this session:\n",
      "{'raw_data_dir': './data/raw_data/', 'processed_data_dir': './data/processed/', 'kernel_rates_dir': './data/analyses/kernel_rates/', 'results_dir': './data/analyses/', 'cols': {'REM': (0.392, 0.549, 0.0784), 'SWS': (0.824, 0.627, 0.0392), 'Wake': (0.0118, 0.235, 0.392), 'measured': (0.3, 0.3, 0.3), 'fit': (0.49, 0.961, 0.961)}}\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import sys, os \n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pickle as pkl\n",
    "\n",
    "# For responsive plot\n",
    "%matplotlib widget\n",
    "\n",
    "# Import shared modules\n",
    "gen_fn_dir = os.path.abspath('.') + '/shared_scripts'\n",
    "sys.path.append(gen_fn_dir)\n",
    "import general_file_fns as gff\n",
    "from binned_spikes_class import spike_counts\n",
    "from dim_red_fns import run_dim_red\n",
    "\n",
    "# Get current date\n",
    "curr_date = datetime.datetime.now().strftime('%Y_%m_%d')+'_'\n",
    "\n",
    "# Load and print general params and create directory to load dimensionality reduction results if needed\n",
    "gen_params = gff.load_pickle_file('./general_params/general_params.pkl')\n",
    "print(f\"General params used for this session:\\n{gen_params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embedding dict with keys:\n",
      "dict_keys(['Wake', 'meas_angles'])\n"
     ]
    }
   ],
   "source": [
    "# Load projections from pickle files created by dim_red\n",
    "embeddings_path = \"./data/analyses/dim_red/Mouse28-140313_Wake_iso_3_embeddings_2023_06_12_.pkl\"\n",
    "with open(embeddings_path, \"rb\") as f:\n",
    "    embeddings = pkl.load(f)\n",
    "\n",
    "print(f\"Loaded embedding dict with keys:\")\n",
    "print(embeddings.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load used params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded params used in dim_red part:\n",
      "{'session': 'Mouse28-140313', 'fit_dim': 3, 'nKnots': 15, 'knot_order': 'wt_per_len', 'penalty_type': 'mult_len', 'nTests': 10, 'train_frac': 0.8, 'area': 'ADn', 'state': 'Wake', 'dt_kernel': 0.1, 'sigma': 0.1, 'method': 'iso', 'n_neighbors': 5, 'dt': 0.1, 'target_dim': 3, 'desired_nSamples': 15000}\n"
     ]
    }
   ],
   "source": [
    "params_path = \"./data/analyses/dim_red/Mouse28-140313_Wake_iso_3_used_params_2023_06_12_.pkl\"\n",
    "with open(params_path, \"rb\") as f:\n",
    "    params = pkl.load(f)\n",
    "\n",
    "print(f\"Loaded params used in dim_red part:\")\n",
    "print(params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_manifold = embeddings[params['state']]\n",
    "nPoints = len(current_manifold)\n",
    "nTrain = np.round(params['train_frac'] * params['nPoints']).astype(int)\n",
    "\n",
    "# Use measured angles to set origin and direction of coordinate increase\n",
    "ref_angles = embeddings['meas_angles']\n",
    "fit_params = {'dalpha' : 0.005, 'knot_order' : params['knot_order'], 'penalty_type' : params['penalty_type'], 'nKnots' : params['nKnots']}\n",
    "\n",
    "results = {}\n",
    "tic = time.time()\n",
    "k = (session, params['fit_dim'], nKnots, knot_order, penalty_type, train_frac)\n",
    "print('Fitting manifold')\n",
    "for curr_sample in range(nTests):\n",
    "    curr_fit_params = dict(fit_params)\n",
    "        \n",
    "    train_idx = np.random.choice(nPoints, size=nTrain, replace=False)\n",
    "    test_idx = np.array([idx for idx in range(nPoints) if idx not in train_idx])\n",
    "    data_to_fit = current_manifold[train_idx].copy()\n",
    "    data_to_decode = current_manifold[test_idx].copy()\n",
    "\n",
    "    curr_fit_result = mff.fit_manifold(data_to_fit, curr_fit_params)\n",
    "    dec_angle, mse = mff.decode_from_passed_fit(data_to_decode, curr_fit_result['tt'][:-1], \n",
    "        curr_fit_result['curve'][:-1], ref_angles[test_idx])\n",
    "    if k in results:\n",
    "        results[k].append([mse, curr_fit_result['fit_err'], \n",
    "            np.array(curr_fit_result['final_knots'])])\n",
    "    else:\n",
    "        results[k] = [[mse, curr_fit_result['fit_err'], \n",
    "            np.array(curr_fit_result['final_knots'])]]\n",
    "print('Time ', time.time()-tic)\n",
    "\n",
    "to_save = {'fit_results' : results, 'session' : session, 'area' : area, 'state' : state, \n",
    "    'embeddings_file' : embeddings_fname} \n",
    "gff.save_pickle_file(to_save, dir_to_save + '%s_%s_dim%d_trainfrac%.2f_decode_errors_sd%d.pkl'%(\n",
    "    session, state, fit_dim, train_frac, sd))\n",
    "\n",
    "rmse_to_plot = np.sqrt([x[0] for x in results[k]])\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "if nTests<20:\n",
    "    ax.scatter(np.ones_like(rmse_to_plot), rmse_to_plot)\n",
    "    ax.set_xticks([1])\n",
    "    # ax.set_xticklabels(['Samples'])\n",
    "else:\n",
    "    vp = ax.violinplot([rmse_to_plot], positions=[1], points=100,\n",
    "        widths=0.75, showmeans=True, showextrema=False, showmedians=True)\n",
    "ax.set_xlim([0,2])\n",
    "ax.set_ylabel('Root mean squared error (rad)')\n",
    "ax.set_ylim([0,1.8])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run persistent homology\n",
    "Running this notebook will:\n",
    "- Use Ripser to get Betti bar codes from saved rates. \n",
    "- If nCells > 10, dim reduce spike counts using Isomap. \n",
    "- Threshold out low density points if thresholded is True.\n",
    "\n",
    "**Ripster note:** required ripser package version can be installed on Ubuntu with:\n",
    "```\n",
    "pip install Cython\n",
    "pip install ripser==0.3.2\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from ./general_params/general_params.pkl...\n",
      "Reading data from ./general_params/general_params.pkl...\n",
      "Making ./data/analyses//TDA\n",
      "Session: Mouse28-140313, state: Wake\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import sys, os\n",
    "import time, datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from ripser import ripser as tda\n",
    "\n",
    "# Set random seed and get current date\n",
    "sd = int((time.time()%1)*(2**31))\n",
    "np.random.seed(sd)\n",
    "curr_date=datetime.datetime.now().strftime('%Y_%m_%d')+'_'\n",
    "\n",
    "# Import shared scirpts\n",
    "gen_fn_dir = os.path.abspath('.') + '/shared_scripts'\n",
    "sys.path.append(gen_fn_dir)\n",
    "\n",
    "import general_file_fns as gff\n",
    "from binned_spikes_class import spike_counts\n",
    "from dim_red_fns import run_dim_red\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn import neighbors\n",
    "\n",
    "# Load general params\n",
    "gen_params = gff.load_pickle_file('./general_params/general_params.pkl')\n",
    "\n",
    "# Create directory for results\n",
    "save_dir = gff.return_dir(gen_params['results_dir'] + \"/TDA\")\n",
    "\n",
    "# Set up parameters\n",
    "session = 'Mouse28-140313'\n",
    "state = 'Wake'\n",
    "thresholded = False\n",
    "area = 'ADn'\n",
    "dt_kernel = 0.1\n",
    "sigma = 0.1\n",
    "d_idx = 10\n",
    "rate_params = {'dt': dt_kernel, 'sigma': sigma}\n",
    "print(('Session: %s, state: %s' % (session, state)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and smooth kernel rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_rates = spike_counts(session, rate_params, count_type='rate',anat_region=area)\n",
    "rates_all = session_rates.get_spike_matrix(state)[0]\n",
    "nCells_tot = rates_all.shape[1]\n",
    "n_smooth_samples = np.floor(len(rates_all) / d_idx).astype(int)\n",
    "smooth_rates = np.zeros((n_smooth_samples, nCells_tot))\n",
    "for i in range(n_smooth_samples):\n",
    "    si = i * d_idx\n",
    "    ei = (i + 1) * d_idx\n",
    "    smooth_rates[i] = np.mean(rates_all[si:ei], axis=0)\n",
    "\n",
    "results = {'session': session, 'h0': [], 'h1': [], 'h2': []}\n",
    "\n",
    "# if greater than 10 cells, dim reduce to 10 dims using Isomap\n",
    "fit_dim = 10\n",
    "dr_method = 'iso'\n",
    "n_neighbors = 5\n",
    "dim_red_params = {'n_neighbors': n_neighbors, 'target_dim': fit_dim}\n",
    "if nCells_tot > 10:\n",
    "    rates = run_dim_red(smooth_rates, params=dim_red_params, method=dr_method)\n",
    "else:\n",
    "    rates = smooth_rates\n",
    "\n",
    "# threshold out outlier points with low neighborhood density\n",
    "if thresholded:\n",
    "    # a) find number of neighbors of each point within radius of 1st percentile of all\n",
    "    # pairwise dist.\n",
    "    dist = pdist(rates, 'euclidean')\n",
    "    rad = np.percentile(dist, 1)\n",
    "    neigh = neighbors.NearestNeighbors()\n",
    "    neigh.fit(rates)\n",
    "    num_nbrs = np.array(list(map(len, neigh.radius_neighbors(X=rates, radius=rad,\n",
    "                        return_distance=False))))\n",
    "\n",
    "    # b) threshold out points with low density\n",
    "    thresholded_prcnt = 20\n",
    "    threshold = np.percentile(num_nbrs, thresholded_prcnt)\n",
    "    thresholded_rates = rates[num_nbrs > threshold]\n",
    "    rates = thresholded_rates\n",
    "\n",
    "# H0 & H1\n",
    "H1_rates = rates\n",
    "barcodes = tda(H1_rates, maxdim=1, coeff=2)['dgms']\n",
    "results['h0'] = barcodes[0]\n",
    "results['h1'] = barcodes[1]\n",
    "\n",
    "# H2. Need to subsample points for computational tractability if \n",
    "# number of points is large (can go higher but very slow)\n",
    "if len(rates) > 1500:\n",
    "    idx = np.random.choice(np.arange(len(rates)), 1500, replace=False)\n",
    "    H2_rates = rates[idx]\n",
    "else:\n",
    "    H2_rates = rates\n",
    "barcodes = tda(H2_rates, maxdim=2, coeff=2)['dgms']\n",
    "results['h2'] = barcodes[2]\n",
    "\n",
    "# save\n",
    "gff.save_pickle_file(results, save_dir + '%s_%s%s_ph_barcodes.p' % (session, state, ('_thresholded' * thresholded)))\n",
    "\n",
    "# If plotting from a saved file, uncomment this and replace with appropriate file.\n",
    "# results = gff.load_pickle_file(gen_params['results_dir'] + '2019_03_22_tda/Mouse28-140313_Wake_ph_barcodes.p')\n",
    "\n",
    "if plot_barcode:\n",
    "    col_list = ['r', 'g', 'm', 'c']\n",
    "    h0, h1, h2 = results['h0'], results['h1'], results['h2']\n",
    "    # replace the infinity bar (-1) in H0 by a really large number\n",
    "    h0[~np.isfinite(h0)] = 100\n",
    "    # Plot the longest barcodes only\n",
    "    plot_prcnt = [99, 98, 90] # order is h0, h1, h2\n",
    "    to_plot = []\n",
    "    for curr_h, cutoff in zip([h0, h1, h2], plot_prcnt):\n",
    "         bar_lens = curr_h[:,1] - curr_h[:,0]\n",
    "         plot_h = curr_h[bar_lens > np.percentile(bar_lens, cutoff)]\n",
    "         to_plot.append(plot_h)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    gs = gridspec.GridSpec(3, 4)\n",
    "    for curr_betti, curr_bar in enumerate(to_plot):\n",
    "        ax = fig.add_subplot(gs[curr_betti, :])\n",
    "        for i, interval in enumerate(reversed(curr_bar)):\n",
    "            ax.plot([interval[0], interval[1]], [i, i], color=col_list[curr_betti],\n",
    "                lw=1.5)\n",
    "        # ax.set_xlim([0, xlim])\n",
    "        # ax.set_xticks([0, xlim])\n",
    "        ax.set_ylim([-1, len(curr_bar)])\n",
    "        # ax.set_yticks([])\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
